@article{adamopoulou2020chatbots,
  author  = {Adamopoulou, E. and Moussiades, L.},
  year    = {2020},
  title   = {Chatbots: History, Technology, and Applications},
  journal = {Machine Learning with Applications}
}

@inproceedings{jw3002020,
  author    = {Agyemang, A. and others},
  title     = {JW300: A Wide-Coverage Parallel Corpus for Low-Resource Languages},
  booktitle = {Proceedings of the 12th International Conference on Language Resources and Evaluation (LREC 2020)},
  year      = {2020},
  pages     = {335--345},  % Verify exact page range from source
  url       = {https://aclanthology.org/2020.lrec-1.335/}
}

@article{alabi2022afriberta,
  author  = {Alabi, J. and others},
  year    = {2022},
  title   = {Adapting Pre-trained Language Models to African Languages via Multilingual Adaptive Fine-Tuning},
  note    = {arXiv preprint arXiv:2204.06487},
  url     = {https://arxiv.org/abs/2204.06487}
}

@inproceedings{banitaba2024,
  author    = {Banitaba, F. S. and Aygun, S. and Najafi, M. H.},
  year      = {2024},
  title     = {Late Breaking Results: Fortifying Neural Networks: Safeguarding Against Adversarial Attacks with Stochastic Computing},
  booktitle = {arXiv preprint},
  eprint    = {2407.04861}
}
@article{brown2020language,
  author  = {Brown, T. B. and Mann, B. and Ryder, N. and others},
  year    = {2020},
  title   = {Language Models are Few-Shot Learners},
  journal = {Advances in Neural Information Processing Systems},
  volume  = {33}
}

@inproceedings{XLM-R,
  author    = {Conneau, A. and Khandelwal, K. and Goyal, N. and Chaudhary, V. and Wenzek, G. and Guzmán, F. and Grave, E. and Ott, M. and Zettlemoyer, L. and Joulin, A.},
  title     = {Unsupervised Cross-lingual Representation Learning at Scale},
  booktitle = {Proceedings of the 58th Annual Meeting of the Association for Computational Linguistics},
  year      = {2020}
}

@article{chang2024prompt,
  author  = {Chang, S. and Fosler-Lussier, E.},
  year    = {2024},
  title   = {How to Prompt LLMs for Text-to-SQL: A Study in Zero-Shot, Single-Domain, and Cross-Domain Settings},
  journal = {NeurIPS 2023 Table Representation Learning Workshop},
  address = {Columbus, OH}
}

@article{chen2021,
  author  = {Chen, M. and Tworek, J. and Jun, H. and others},
  year    = {2021},
  title   = {Evaluating Large Language Models Trained on Code},
  journal = {arXiv preprint},
  eprint  = {2107.03374}
}


@article{chen2023teaching,
  author  = {Chen, X. and Lin, M. and Schärli, N. and Zhou, D.},
  year    = {2023},
  title   = {Teaching Large Language Models to Self-Debug},
  journal = {arXiv preprint},
  eprint  = {2304.05128}
}

@misc{chen2023evaluating,
  title={Evaluating Generalization in Text-to-SQL Parsing},
  author={Chen, Xiang and others},
  year={2023},
  note={arXiv:2305.11589}
}

@article{codd1970relational,
  title={A relational model of data for large shared data banks},
  author={Codd, Edgar F},
  journal={Communications of the ACM},
  volume={13},
  number={6},
  pages={377--387},
  year={1970},
  publisher={ACM}
}

@article{conneau2019xlm,
  author  = {Conneau, A. and Lample, G.},
  year    = {2019},
  title   = {Cross-lingual Language Model Pretraining},
  journal = {Advances in Neural Information Processing Systems}
}

@book{date2004introduction,
  title={An Introduction to Database Systems},
  author={Date, C.J.},
  year={2004},
  publisher={Addison Wesley}
}


@article{dettmers2023qlora,
  title={QLoRA: Efficient Finetuning of Quantized LLMs},
  author={Dettmers, Tim and others},
  journal={arXiv preprint arXiv:2305.14314},
  year={2023}
}

@article{devlin2018bert,
  title={BERT: Pre-training of Deep Bidirectional Transformers for Language Understanding},
  author={Devlin, Jacob and Chang, Ming-Wei and Lee, Kenton and Toutanova, Kristina},
  journal={arXiv preprint arXiv:1810.04805},
  year={2018}
}

@article{dong2023c3,
  author  = {Dong, X. and Zhang, C. and Ge, Y. and others},
  year    = {2023},
  title   = {C3: Zero-Shot Text-to-SQL with ChatGPT},
  journal = {arXiv preprint},
  eprint  = {2307.07306}
}

@article{dou2022multispider,
  author  = {Dou, Z. and Sherry, D. and Johnson, M.},
  year    = {2022},
  title   = {MultiSpider: A Massively Multilingual Text-to-SQL Benchmark},
  journal = {Findings of EMNLP}
}

@article{einolghozati2021dialect2sql,
  author  = {Einolghozati, P. and Azizi, M. and Joty, S. R.},
  year    = {2021},
  title   = {Dialect2SQL: Bridging Dialectal Arabic and SQL Parsing},
  journal = {North American Chapter of the Association for Computational Linguistics}
}

@misc{fortune2024global500,
  author  = {{Fortune}},
  title   = {Fortune Global 500 2024},
  year    = {2024},
  url     = {https://fortune.com/ranking/global500/},
  note    = {Retrieved 2024}
}

@article{gan2021exploring,
  author  = {Gan, Y. and Chen, X. and Purver, M.},
  year    = {2021},
  title   = {Exploring Underexplored Limitations of Cross-Domain Text-to-SQL Generalization},
  journal = {arXiv preprint},
  eprint  = {2109.05157}
}

@article{gao2024texttosql,
  author  = {Gao, D. and Wang, H. and Li, Y. and others},
  year    = {2024},
  title   = {Text-to-SQL Empowered by Large Language Models: A Benchmark Evaluation},
  journal = {Proceedings of the VLDB Endowment},
  volume  = {17},
  number  = {5},
  pages   = {1132--1145},
  doi     = {10.14778/3641204.3641221}
}

@inproceedings{Gao2021,
  author    = {Gao, T. and Fisch, A. and Chen, D.},
  title     = {Making Pre-trained Language Models Better Few-shot Learners},
  booktitle = {Proceedings of the 59th Annual Meeting of the Association for Computational Linguistics},
  year      = {2021}
}

@article{goyal2022flores,
  author  = {Goyal, N. and Gao, C. and Chaudhary, V. and others},
  year    = {2022},
  title   = {The Flores-101 Evaluation Benchmark for Low-Resource and Multilingual Machine Translation},
  journal = {Transactions of the Association for Computational Linguistics},
  volume  = {10},
  pages   = {522--538},
  doi     = {10.1162/tacl_a_00474}
}

@article{guo2019,
  author  = {Guo, T. and Gao, H.},
  year    = {2019},
  title   = {Content Enhanced BERT-Based Text-to-SQL Generation},
  journal = {arXiv preprint},
  eprint  = {1910.07179}
}

@article{hammami2021,
  author  = {Hammami, L. and Paglialonga, A. and Pruneri, G. and others},
  year    = {2021},
  title   = {Automated Classification of Cancer Morphology from Italian Pathology Reports Using Natural Language Proc@misc{li2023bird,
  title={BIRD: Benchmarks for Individualized Realistic Databases},
  author={Li, Jiayi and others},
  year={2023},
  howpublished={arXiv preprint arXiv:2306.01678},
  note={Accessed: 2024-05-01}
}essing Techniques},
  journal = {Journal of Biomedical Informatics},
  volume  = {116},
  pages   = {103712}
}

@article{hong2024nextgen,
  author  = {Hong, Z. and Yuan, Z. and Zhang, Q. and others},
  year    = {2024},
  title   = {Next-Generation Database Interfaces: A Survey of LLM-Based Text-to-SQL},
  journal = {arXiv preprint},
  eprint  = {2406.08426}
}

@inproceedings{Houlsby2019,
  author    = {Houlsby, N. and Giurgiu, A. and Jastrzebski, S. and Morrone, B. and {De Laroussilhe}, Q. and Gesmundo, A. and Attariyan, M. and Gelly, S.},
  title     = {Parameter-efficient transfer learning for NLP},
  booktitle = {Proceedings of the 36th International Conference on Machine Learning},
  year      = {2019}
}


@article{Hu2021,
  author  = {Hu, E. J. and Shen, Y. and Wallis, P. and Allen-Zhu, Z. and Li, Y. and Wang, S. and Chen, W.},
  title   = {LoRA: Low-Rank Adaptation of Large Language Models},
  year    = {2021},
  journal = {arXiv preprint},
  eprint  = {2106.09685},
  url     = {https://arxiv.org/abs/2106.09685}

@misc{mixtral2023ofexperts,
  title={Mixtral of Experts: Sparse Mixture of Experts for Efficient Language Modeling},
  author={Jiang, Albert Q. and Sablayrolles, Alexandre and Roux, Antoine and Mensch, Arthur and Savary, Blanche and Bamford, Chris and Chaplot, Devendra Singh and de las Casas, Diego and Bou Hanna, Emma and Bressand, Florian and Lengyel, Gianna and Bour, Guillaume and Lample, Guillaume and Lavaud, Lélio Renard and Saulnier, Lucile and Lachaux, Marie-Anne and Stock, Pierre and Subramanian, Sandeep and Yang, Sophia and Antoniak, Szymon and Le Scao, Teven and Gervet, Théophile and Lavril, Thibaut and Wang, Thomas and Lacroix, Timothée and El Sayed, William},
  year={2023},
  howpublished={\url{https://mistral.ai/news/mixtral-of-experts/}},
  note={Accessed: 2024-05-01}
}


@article{joshi2020state,
  author  = {Joshi, P. and Santy, S. and Budhiraja, A. and others},
  year    = {2020},
  title   = {The State and Fate of Linguistic Diversity and Inclusion in the NLP World},
  journal = {Proceedings of the 58th Annual Meeting of the Association for Computational Linguistics}
}

@article{kanburoglu2024texttosql,
  author  = {Kanburoğlu, A. B. and Tek, F. B.},
  year    = {2024},
  title   = {Text-to-SQL: A Methodical Review of Challenges and Models},
  journal = {Turkish Journal of Electrical Engineering and Computer Sciences},
  volume  = {32},
  number  = {3},
  pages   = {403--419},
  doi     = {10.14778/3641204.3641221}
}

@article{kang2013,
  author  = {Kang, N. and Singh, B. and Afzal, Z. and others},
  year    = {2013},
  title   = {Using Rule-Based Natural Language Processing to Improve Disease Normalization in Biomedical Text},
  journal = {Journal of the American Medical Informatics Association},
  volume  = {20},
  number  = {5},
  pages   = {876--881}
}

@article{katsogiannis2021,
  author  = {Katsogiannis-Meimarakis, G. and Koutrika, G.},
  year    = {2021},
  title   = {A Deep Dive into Deep Learning Approaches for Text-to-SQL Systems},
  journal = {Proceedings of the 2021 International Conference on Management of Data},
  pages   = {2846--2851}
}

@article{Kumar2022,
  author  = {Kumar, A. and Nagarkar, P. and Nalhe, P. and Vijayakumar, S.},
  year    = {2022},
  title   = {Deep learning driven natural languages text to SQL query conversion: A survey},
  journal = {arXiv preprint},
  eprint  = {2208.04415},
  url     = {https://arxiv.org/abs/2208.04415}
}

@inproceedings{LampleConneau2019,
  author    = {Lample, G. and Conneau, A.},
  title     = {Cross-lingual Language Model Pretraining},
  booktitle = {Advances in Neural Information Processing Systems},
  year      = {2019},
  volume    = {32}
}

@inproceedings{Lester2021,
  author    = {Lester, B. and Al-Rfou, R. and Constant, N.},
  title     = {The Power of Scale for Parameter-Efficient Prompt Tuning},
  booktitle = {Proceedings of the 2021 Conference on Empirical Methods in Natural Language Processing},
  year      = {2021}
}

@inproceedings{li2014constructing,
  author    = {Li, F. and Jagadish, H. V.},
  title     = {Constructing an interactive natural language interface for relational databases},
  booktitle = {Proceedings of the International Conference on Very Large Data Bases (VLDB)},
  year      = {2014},
  pages     = {78--82}  % Add page numbers if available
}

@article{li2018,
  author  = {Li, H.},
  year    = {2018},
  title   = {Deep Learning for Natural Language Processing: Advantages and Challenges},
  journal = {National Science Review},
  volume  = {5},
  number  = {1},
  pages   = {24--26}
}

@inproceedings{li2023bird,
  title={Can LLM Already Serve as A Database Interface? A BIg Bench for Large-Scale Database Grounded Text-to-SQLs},
  author={Li, Jiayi and Qin, Lianhui and Lu, Xiao and Xu, Jialong and Xu, Yankai and Yang, Zonghai and Wang, Yuwei and Huang, Minlie},
  booktitle={Proceedings of the 61st Annual Meeting of the Association for Computational Linguistics (ACL)},
  year={2023},
  url={https://arxiv.org/abs/2306.01678}
}


@inproceedings{Li2021,
  author    = {Li, X. and Liang, P.},
  title     = {Prefix-Tuning: Optimizing Continuous Prompts for Generation},
  booktitle = {Proceedings of the 59th Annual Meeting of the Association for Computational Linguistics},
  year      = {2021}
}

@article{liu2023comprehensive,
  author  = {Liu, A. and Hu, X. and Wen, L. and Yu, P. S.},
  year    = {2023},
  title   = {A Comprehensive Evaluation of ChatGPT's Zero-Shot Text-to-SQL Capability},
  journal = {arXiv preprint},
  eprint  = {2303.13547}
}


@article{mahmud2015,
  author  = {Mahmud, T. and Hasan, K. A. and Ahmed, M. and Chak, T. H. C.},
  year    = {2015},
  title   = {A Rule Based Approach for NLP Based Query Processing},
  journal = {2015 2nd International Conference on Electrical Information and Communication Technologies (EICT)},
  pages   = {78--82}
}

@dataset{matekenya2022,
  author  = {Matekenya, D.},
  year    = {2022},
  title   = {Chichewa Speech Dataset},
  url     = {https://doi.org/10.5281/zenodo.6595625},
  note    = {Zenodo}
}

@article{min2023,
  author  = {Min, B. and Ross, H. and Sulem, E. and others},
  year    = {2023},
  title   = {Recent Advances in Natural Language Processing via Large Pre-Trained Language Models: A Survey},
  journal = {ACM Computing Surveys},
  volume  = {56},
  number  = {2}
}

@article{mohammadjafari2023natural,
  author  = {Mohammadjafari, A. and Maida, A. S. and Gottumukkala, R.},
  year    = {2023},
  title   = {From Natural Language to SQL: Review of LLM-Based Text-to-SQL Systems},
  journal = {arXiv preprint},
  eprint  = {2410.01066},
  doi     = {10.48550/arXiv.2410.01066}
}

@article{nllb2022,
  author  = {{Meta AI Research Team}},
  year    = {2022},
  title   = {No Language Left Behind: Scaling Human-Centered Machine Translation},
  journal = {arXiv preprint},
  eprint  = {2207.04672}

}@inproceedings{masakhane2020,
  author    = {Nekoto, W. and others},
  title     = {Participatory Research for Low-Resource Machine Translation: A Case Study in African Languages},
  booktitle = {Proceedings of the 2020 Conference on Empirical Methods in Natural Language Processing: Findings},
  year      = {2020},
  pages     = {195--210},  % Verify exact page range from source
  url       = {https://aclanthology.org/2020.findings-emnlp.195/}
}

@article{openai2023,
  author  = {{OpenAI}},
  year    = {2023},
  title   = {GPT-4 Technical Report},
  journal = {arXiv preprint},
  eprint  = {2303.08774}
}

@article{pan2010survey,
  author  = {Pan, S. J. and Yang, Q.},
  year    = {2010},
  title   = {A Survey on Transfer Learning},
  journal = {IEEE Transactions on Knowledge and Data Engineering},
  volume  = {22},
  number  = {10},
  pages   = {1345--1359}
}

@article{poesia2022synchromesh,
  author  = {Poesia, G. and Polozov, O. and Le, V. and others},
  year    = {2022},
  title   = {Synchromesh: Reliable Code Generation from Pre-Trained Language Models},
  journal = {arXiv preprint},
  eprint  = {2201.11227}
}

@article{rajkumar2022,
  author  = {Rajkumar, N. and Li, R. and Bahdanau, D.},
  year    = {2022},
  title   = {Evaluating the Text-to-SQL Capabilities of Large Language Models},
  journal = {arXiv preprint},
  eprint  = {2204.00498}
}

@article{scholak2021picard,
  author  = {Scholak, P. and Elazar, Y. and Goldberg, Y.},
  year    = {2021},
  title   = {PICARD: Pretrained Autoregressive Constrained Decoding for Text-to-SQL Parsing},
  journal = {EMNLP}
}

@article{sennrich2016back,
  author  = {Sennrich, R. and Haddow, B. and Birch, A.},
  year    = {2016},
  title   = {Improving Neural Machine Translation Models with Monolingual Data},
  journal = {ACL}
}

@article{shu2023transcending,
  author  = {Shu, P. and Chen, J. and Liu, Z. and others},
  year    = {2023},
  title   = {Transcending Language Boundaries: Harnessing LLMs for Low-Resource Language Translation},
  journal = {arXiv preprint},
  eprint  = {2411.11295}
}

@inproceedings{oscar2019,
  author    = {Suárez, P. J. and others},
  title     = {Asynchronous Pipeline for Processing Huge Corpora on Medium to Low Resource Infrastructures},
  booktitle = {Proceedings of the Workshop on Challenges in the Management of Large Corpora (CMLC)},
  year      = {2019},
  pages     = {33--43},  % Verify exact page range from source
  url       = {https://aclanthology.org/W19-4820/}
}

@article{Tahir2024,
  author  = {Tahir, M. H. and Shams, S. and Fiaz, L. and Adeeba, F. and Hussain, S.},
  year    = {2024},
  title   = {Benchmarking pre-trained large language models' potential across Urdu NLP tasks},
  journal = {arXiv preprint},
  eprint  = {2405.15453},
  url     = {https://arxiv.org/abs/2405.15453}
}

@dataset{taylor2020,
  author  = {Taylor, A.},
  year    = {2020},
  title   = {SpokenChichewaCorpus (1.0)},
  url     = {https://doi.org/10.5281/zenodo.3731994},
  note    = {Zenodo}
}

@article{taylor2024assessing,
  author  = {Taylor, A. and Kazembe, P.},
  year    = {2024},
  title   = {Assessing Language Barriers in Health Facilities in Malawi},
  journal = {BMC Health Services Research},
  volume  = {24},
  number  = {1},
  pages   = {1393},
  doi     = {10.1186/s12913-024-11901-4}
}

@article{touvron2023,
  author  = {Touvron, H. and Lavril, T. and Izacard, G. and others},
  year    = {2023},
  title   = {LLaMA: Open and Efficient Foundation Language Models},
  journal = {arXiv preprint},
  eprint  = {2302.13971}
}

@inproceedings{vaswani2017attention,
  title={Attention is all you need},
  author={Vaswani, Ashish and others},
  booktitle={Advances in neural information processing systems},
  year={2017}
}

@article{Wang2023,
  author  = {Wang, H. and Li, J. and Wu, H. and Hovy, E. and Sun, Y.},
  year    = {2023},
  title   = {Pre-trained language models and their applications},
  journal = {Engineering},
  volume  = {25},
  pages   = {51--65}
}

@inproceedings{wei2019eda,
  author    = {Wei, J. and Zou, K.},
  title     = {EDA: Easy data augmentation techniques for boosting performance on text classification tasks},
  booktitle = {Proceedings of the 2019 Conference on Empirical Methods in Natural Language Processing (EMNLP)},
  year      = {2019},
  pages     = {6381--6387},
  url       = {https://aclanthology.org/D19-1670/}
}

@misc{deepseek2024longtermism,
  title     = {DeepSeek LLM: Scaling Open-Source Language Models with Longtermism},
  author    = {Xiao, B. and Deli, C. and Guanting, C. and Shanhuang, C. and Damai, D. and Chengqi, D. and Honghui, D. and Kai, D. and Qiushi, D. and Zhe, F. and Huazuo, G. and Kaige, G. and Wenjun, G. and Ruiqi, G. and others},
  year      = {2024},
  howpublished = {\url{https://huggingface.co/deepseek-ai}},

}


@article{yu2019cosql,
  author  = {Yu, T. and Zhang, R. and Er, H. Y. and Li, S. and Xue, E. and Pang, B. and Lin, X. V. and Tan, Y. C. and Shi, T. and Li, Z. and others},
  year    = {2019},
  title   = {CoSQL: A conversational text-to-SQL challenge towards cross-domain natural language interfaces to databases},
  journal = {arXiv preprint},
  eprint  = {1909.05378},
  url     = {https://arxiv.org/abs/1909.05378}
}
@article{yu2018spider,
  author  = {Yu, T. and Zhang, R. and Zhong, V. and others},
  year    = {2018},
  title   = {Spider: A Large-Scale Human-Labeled Dataset for Complex and Cross-Domain Semantic Parsing and Text-to-SQL Task},
  journal = {EMNLP}
}

@article{zhang2024retrieval,
  author  = {Zhang, X. and Meng, Q. and Bos, J.},
  title   = {Retrieval-Augmented Semantic Parsing: Using Large Language Models to Improve Generalization},
  year    = {2024},
  journal = {arXiv preprint},
  note    = {Submitted on 13 Dec 2024},
  url     = {https://arxiv.org/abs/XXXX.XXXXX}  % Add actual arXiv URL when available
}

@article{zhao2023survey,
  author  = {Zhao, W. X. and Zhou, K. and Li, J. and others},
  year    = {2023},
  title   = {A Survey of Large Language Models},
  journal = {arXiv preprint},
  eprint  = {2303.18223}
}

@article{zhu2005ssl,
  author  = {Zhu, X.},
  year    = {2005},
  title   = {Semi-Supervised Learning Literature Survey},
  institution = {University of Wisconsin-Madison}
}
